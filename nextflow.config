/*
 * -------------------------------------------------
 *  csgenetics_scrnaseq Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

manifest {
    name            = 'csgenetics_scrnaseq'
    author          = ''
    homePage        = 'https://github.com/csgenetics/csgenetics_scrnaseq'
    description     = 'Pipeline for processing CS Genetics single cell RNA-Seq data'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=25.10.2'
    version = '1.1.17'
}

// Enable strict syntax mode for Nextflow 25.10.2+
nextflow.enable.strict = true

// Global default params, used in configs
params { 
  // Path to comma-separated file containing information about the samples in the experiment
  input_csv = null
  // The output directory where the results will be saved. You have to use absolute paths to storage on Cloud infrastructure.
  outdir = './results'
  
  // Path to the comma-separated file containing the list of CS Genetics cell barcodes
  barcode_list_path = "s3://csgx.public.readonly/resources/barcode_lists/IDT_IO_kit_v2.csv"
  // Path to the tab-separated file containing barcode correction list with 1-Hamming distance variants
  barcode_correction_list_path = "s3://csgx.public.readonly/resources/barcode_correction_lists/IDT_IO_kit_v2_correction_list.tsv"
  // Pattern of 13bp io barcode, each C represents one base of the barcode
  barcode_pattern="CCCCCCCCCCCCC"


  // The minimum total counts for a given barcode to classify it as a cell.
  minimum_count_threshold = 100

  sss_nmer = 8

  // AWS Batch
  awsregion = null
  awsqueue = null

  // Default maximum resource limits for individual processes (expected to be overwritten)
  max_memory = 256.GB
  max_cpus = 16
  max_time = 240.h

}


profiles {
  local {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    process.executor = 'local'
  }
  docker {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/images.config'
    docker.enabled=true
    docker.runOptions = '-u $(id -u):$(id -g)'
  }
  singularity {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/images.config'
    singularity.enabled=true
  }
  conda {
    // For users who cannot run Docker/Singularity containers
    // Use conda environments for all software dependencies
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/conda_envs.config'
    conda.enabled = true
    conda.createTimeout = '60 min'  // Allow time for complex environments
  }
  test {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/test.config'
    includeConfig 'conf/images.config'
    docker.enabled=true
    docker.runOptions = '-u $(id -u):$(id -g)'
  }
  test_pbmc_4_sample_full {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/test_pbmc_4_sample_full.config'
    includeConfig 'conf/images.config'
    docker.enabled=true
    docker.runOptions = '-u $(id -u):$(id -g)'
  }
  test_hsap_mmus_2_sample_full {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/test_hsap_mmus_2_sample_full.config'
    includeConfig 'conf/images.config'
    docker.enabled=true
    docker.runOptions = '-u $(id -u):$(id -g)'
  }
  test_singularity{
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/test.config'
    includeConfig 'conf/images.config'
    singularity.enabled=true
  }
  test_conda{
    // Test profile using conda environments instead of containers
    // Uses the same test dataset as test_singularity
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/test.config'
    includeConfig 'conf/conda_envs.config'
    conda.enabled = true
    conda.createTimeout = '60 min'
  }
  aws{
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/aws.config'
  }
}

// Set the local executor RAM and CPU limits
executor {
  cpus = 16
  memory = '256 GB'
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
  PYTHONNOUSERSITE = 1
  R_PROFILE_USER = "/.Rprofile"
  R_ENVIRON_USER = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Resource limits - replaces check_max function (Nextflow 24.04+)
// These limits cap task resource requests to prevent unschedulable jobs
process.resourceLimits = [
  cpus: params.max_cpus,
  memory: params.max_memory,
  time: params.max_time
]

timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline.html"
    overwrite = true
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report.html"
    overwrite = true
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace.txt"
    overwrite = true
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag.html"
    overwrite = true
}

// Note: The check_max() function has been removed as part of the migration to strict syntax.
// Resource limits are now enforced through process.resourceLimits (configured above).
// Individual process resource requirements are defined directly in conf/base.config.
