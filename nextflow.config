/*
 * -------------------------------------------------
 *  csgenetics_scrnaseq Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

manifest {
    name            = 'csgenetics_scrnaseq'
    author          = ''
    homePage        = 'https://github.com/csgenetics/csgenetics_scrnaseq'
    description     = 'Pipeline for processing CS Genetics single cell RNA-Seq data'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=24.04.3'
    version = '1.1.8'
}

// Global default params, used in configs
params {
  // Path to comma-separated file containing information about the samples in the experiment
  input_csv = null
  // The output directory where the results will be saved. You have to use absolute paths to storage on Cloud infrastructure.
  outdir = './results'
  
  // Path to the comma-separated file containing the list of CS Genetics cell barcodes
  barcode_list_path = "s3://csgx.public.readonly/resources/barcode_lists/IDT_IO_kit_v2.csv"
  // Pattern of 13bp io barcode, each C represents one base of the barcode
  barcode_pattern="CCCCCCCCCCCCC"

  // If provided, this variable selects a suite of pre-configured parameters related to the reference genome and annotation files
  // Alternatively you can specify the genome and annotation GTF directly (see below)
  genome = ""

  // These parameters should only be set if the genome parameter is not set.
  // Path to the STAR index directory. This should be built with a STAR version compatible with STAR version 2.7.11b
  star_index = ""
  gtf = ""
  mitochondria_chromosome = ""
  mixed_species = false

  // The pipeline currently only supports the CS Genetics curated Hsap Mmus mixed species analysis.
  // Here we set the prameters used for the mixed species analyses to empty strings.
  // These should be left as empty strings for single species analyses.
  // To run a mixed species analysis, set the genome value above. Doing this
  // will automatically set the below parameters to the correct values.
  hsap_mitochondria_chromosome = ""
  mmus_mitochondria_chromosome = ""
  hsap_gene_prefix = ""
  mmus_gene_prefix = ""

  // The minimum total counts for a given barcode to classify it as a cell.
  minimum_count_threshold = 100

  sss_nmer = 8

  // AWS Batch
  awsregion = null
  awsqueue = null

  // Default maximum resource limits for individual processes (expected to be overwritten)
  max_memory = 256.GB
  max_cpus = 16
  max_time = 240.h

}


profiles {
  local {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    process.executor = 'local'
  }
  docker {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/images.config'
    docker.enabled=true
    docker.runOptions = '-u $(id -u):$(id -g)'
  }
  singularity {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/images.config'
    singularity.enabled=true
  }
  test {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/test.config'
    includeConfig 'conf/images.config'
    docker.enabled=true
    docker.runOptions = '-u $(id -u):$(id -g)'
  }
  test_pbmc_4_sample_full {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/test_pbmc_4_sample_full.config'
    includeConfig 'conf/images.config'
    docker.enabled=true
    docker.runOptions = '-u $(id -u):$(id -g)'
  }
  test_hsap_mmus_2_sample_full {
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/test_hsap_mmus_2_sample_full.config'
    includeConfig 'conf/images.config'
    docker.enabled=true
    docker.runOptions = '-u $(id -u):$(id -g)'
  }
  test_singularity{
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/test.config'
    includeConfig 'conf/images.config'
    singularity.enabled=true
  }
  aws{
    // Load base.config by default for all pipelines
    // N.B. the base.config includeConfig has to be
    // within each of the profile blocks else the
    // resource allocation will not work properly
    includeConfig 'conf/base.config'
    includeConfig 'conf/genomes.config'
    includeConfig 'conf/aws.config'
  }
}

// Set the local executor RAM and CPU limits
executor {
  cpus = 16
  memory = '256 GB'
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
  PYTHONNOUSERSITE = 1
  R_PROFILE_USER = "/.Rprofile"
  R_ENVIRON_USER = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
